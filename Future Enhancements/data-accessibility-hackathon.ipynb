{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88c6f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "import time\n",
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb12387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY #input your key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "989ea2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4a69c",
   "metadata": {},
   "source": [
    "### Functions to help parse text and call GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f2e37fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def chunk_text(text, max_chunk_size):\n",
    "    #TODO: improve chunking logic\n",
    "    words = word_tokenize(text)\n",
    "    chunks = [words[i:i + max_chunk_size] for i in range(0, len(words), max_chunk_size)]\n",
    "    return [\"\".join(chunk) for chunk in chunks]\n",
    "\n",
    "def chat(input_value, max_tokens, engine = 'text-davinci-003'):\n",
    "#Note: The openai-python library support for Azure OpenAI is in preview. \n",
    "    openai.api_type = \"azure\"\n",
    "    openai.api_base = \"https://eastus.api.cognitive.microsoft.com/\"\n",
    "    openai.api_version = \"2022-12-01\"\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "      engine=engine,\n",
    "      prompt=f\"{input_value}\\n\\n\",\n",
    "      temperature=1,\n",
    "      max_tokens=max_tokens,\n",
    "      top_p=0.5,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "      stop=None)\n",
    "    return response.choices[0].text\n",
    "\n",
    "def chunk_gpt_response(user_input, analysis_text, max_prompt = 3000, max_response_tokens=1000, engine='text-davinci-003'):\n",
    "    prompt_max_len = max_prompt - len(word_tokenize(user_input))\n",
    "    #read in file and convert to text\n",
    "    chunks = chunk_text(analysis_text, prompt_max_len)\n",
    "    results = []\n",
    "    if len(chunks) > 0:\n",
    "        for chunk in chunks:\n",
    "            results.append(chat(user_input + chunk, max_response_tokens))\n",
    "    else:\n",
    "        results.append(chat(user_input, max_response_tokens))\n",
    "    return '\\n'.join(results)\n",
    "\n",
    "\n",
    "def word_tokenize(text):\n",
    "    ids = tokenizer(text)['input_ids']\n",
    "    return [tokenizer.decode(x) for x in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4c0c1",
   "metadata": {},
   "source": [
    "## Functions for extracting useful information from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e4fbdec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits a linear regression model to the data versus the index value\n",
    "def get_slope(data):\n",
    "    summaries = {}\n",
    "    for col in data.columns:\n",
    "        model = sm.OLS(data[col], sm.tools.add_constant(data.index)).fit()\n",
    "        summaries[col] = model.summary()\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "c08e182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for outliers based on a simple z score\n",
    "def get_outliers(data):\n",
    "    summary = data.describe()\n",
    "    # Calculate Z-score for each data point\n",
    "    zscore = (data - summary.loc['mean'])/summary.loc['std']\n",
    "    # Identify data points with Z-score > 3\n",
    "    outlier_dict = {}\n",
    "    for col in data.columns:\n",
    "        outliers = data[col][data[col] > 3]\n",
    "        outlier_dict[col] = outliers\n",
    "    return outlier_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "590bcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data that appears to be geo-related, do a simple groupby and average to get basic summary values\n",
    "def geo_analysis(data, data_explanation = \"\"):\n",
    "    prompt = 'Given the columns of a dataframe below, return the columns that are related to geography as a python list'\n",
    "    geo_columns = chat(prompt + str(list(data.columns)), max_tokens = 1000)\n",
    "    geo_columns = eval(geo_columns)\n",
    "    results = {}\n",
    "    for col in geo_columns:\n",
    "        agg_data = data.groupby(col).mean(numeric_only=True)\n",
    "        if agg_data.shape[1] == 0:\n",
    "            continue\n",
    "        agg_data = agg_data.sort_values(agg_data.columns[0], ascending=False)\n",
    "        agg_data = agg_data.to_dict()\n",
    "        results[col] = chunk_gpt_response(data_explanation + \"Summarize the key insights from the following data. The data is sorted from highest value to lower.\",\n",
    "                                          str(agg_data), 3000, 1000)\n",
    "    return results    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e59799b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepearate analysis if we're looking at geo vs nongeo data - we would likely want to expand the classification at some point\n",
    "def is_geo_data(data):\n",
    "    prompt = \"Below is the first few rows of a dataframe. Return 1 if the data is geography-related, and 0 otherwise\"\n",
    "    return chat(prompt + str(data.head()), 10).replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c0b4e",
   "metadata": {},
   "source": [
    "## Reading in data (i downloaded this manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f5696c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality = pd.read_csv(\"/Users/amitmisra/Downloads/mortality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b223f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this are examples of views that are showed - not sure if we have the \n",
    "mortality_by_country = mortality[mortality.Period == 2019][['ParentLocation', 'Location', 'FactValueNumeric']]\n",
    "mortality_over_time = mortality.groupby('Period').FactValueNumeric.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "5a12df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non-geo dataframes, run the slope and outlier analyses as a simple starting point\n",
    "def non_geo_analysis(data, data_explanation=\"\"):\n",
    "    slope_results = get_slope(data)\n",
    "    slope_gpt = {}\n",
    "    for key in slope_results:\n",
    "        slope_gpt[key] = chunk_gpt_response(data_explanation + f\"Given the following model results for a linear regression model for column {key}, describe the key insights in layment's terms\",\n",
    "                                            str(slope_results[key]), 3000, 1000)\n",
    "    outlier_results = get_outliers(data)\n",
    "    outlier_gpt = {}\n",
    "    for key in outlier_results:\n",
    "        outlier_gpt[key] = chunk_gpt_response(data_explanation + f\"Given the following outliers for column {key}, return the main outliers with their corresponding {key} values:\",\n",
    "                                              str(outlier_results[key]), 1000)\n",
    "    return slope_gpt, outlier_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8d7d6ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the endpoint where you can input a pandas dataframe and an optional explanation of what the data is\n",
    "# providing an explanation will give better results\n",
    "def return_insights(data, data_explanation = \"\"):\n",
    "    if is_geo_data(data) == \"1\":\n",
    "        gpt_results = geo_analysis(data, data_explanation)\n",
    "    else:\n",
    "        gpt_results = non_geo_analysis(data, data_explanation)\n",
    "    summary_prompt = data_explanation + \"Identify the key insights from the following analysis of the data and explain in simple terms. The analysis is formatted as a python dictionary with column names as keys. \"\n",
    "    final_result = chunk_gpt_response(summary_prompt, str(gpt_results), 3000, 1000)\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "39c0069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The key insight from this analysis is that the value of FactValueNumeric has decreased significantly over the past 30 years, from 13.37 in 1990 to 5.62 in 2019. This indicates that the value has decreased over the years, with the highest decrease from 1990 to 2019.\n"
     ]
    }
   ],
   "source": [
    "print(return_insights(mortality_over_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9643b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The key insight from this data is that mortality rates for 5-14 year olds have decreased significantly over time. In 1990, the mortality rate was 13.37 per 100,000 people, but by 2019, it had decreased to 5.62 per 100,000 people. This indicates that mortality rates for this age group have decreased by over 57% in the past 30 years. This suggests that public health initiatives and advances in medical technology have had a positive impact on the mortality rate of this age group.\n"
     ]
    }
   ],
   "source": [
    "print(return_insights(mortality_over_time, \"This is data on mortality rates for 5-14 year olds over time. FactValueNumeric is the mortality rate. \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7eb28a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The key insights from this analysis are that the highest FactValueNumeric is in Africa, with the highest value being in Niger at 30.29. The lowest FactValueNumeric is in Luxembourg at 0.38. The average FactValueNumeric is 8.82, and the majority of countries have a FactValueNumeric between 10 and 5.\n"
     ]
    }
   ],
   "source": [
    "print(return_insights(mortality_by_country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1d63eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The key insights from this analysis are that mortality rates for 5-14 year olds are highest in Africa and lowest in Europe, and that there is a great variation in mortality rates between countries, with Niger having the highest rate and Luxembourg having the lowest.\n"
     ]
    }
   ],
   "source": [
    "print(return_insights(mortality_by_country, \"This is data on mortality rates for 5-14 year olds by country. FactValueNumeric is the mortality rate. \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615514a6",
   "metadata": {},
   "source": [
    "### Results on raw data without any groupbys\n",
    "\n",
    "This shows that this methodology works okay to extract information from the raw csv, but only if we give some guidance on what's in the data and what's important. Otherwise the model will return things that are not really significant.\n",
    "\n",
    "However, once we give some modest direction (which any non-technical person could write), we get results that, while not perfect, do a pretty good job describing the key points from the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "217a3cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The key insight from the data is that all countries have the same period of 2004.5 and IsLatestYear of 0.03333333333333333. This indicates that the data is from the same period and is the most recent data available. Additionally, the data is sorted from highest value to lower, providing an overview of the values in descending order. This allows for a comparison of the values between countries and regions.\n",
      "\n",
      "The key insights from this analysis are: \n",
      "1. It provides information about the highest value, range of values, unit of measure, and any comments associated with the facts. \n",
      "2. It can be used to analyze trends over time and compare different values and measurements. \n",
      "3. It can provide insights into the period, type of dimensions, values, numerical prefixes, numerical values, units of measurement, translations, and comments.\n"
     ]
    }
   ],
   "source": [
    "print(return_insights(mortality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "719f4717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The key insights from this data are that mortality rates for 5-14 year olds vary greatly between countries. The highest rate is in Sierra Leone at 25.9 per 1000, while the lowest rate is in Singapore at 0.7 per 1000. On average, the mortality rate for 5-14 year olds is 8.87 per 1000. The data also shows that mortality rates tend to be higher in African and Asian countries, with many countries in these regions having rates above 20 per 1000. The data also suggests that mortality rates are generally higher in developing countries than in developed countries.\n",
      "\n",
      "The key insights from this data are that mortality rates for 5-14 year olds have been decreasing over time, with the highest mortality rate recorded in 1991 at 13.335589743589743 and the lowest in 2019 at 5.619538461538461. This indicates that there has been a significant improvement in mortality rates over the past two decades. The data also shows that the mortality rate for 5-14 year olds is highest in certain countries, with the highest mortality rate being reported in the Democratic Republic of the Congo. The data also suggests that mortality rates vary from country to country, with some countries having higher rates than others. Finally, the data indicates that the lowest mortality rate is in Singapore, with a rate of 0.3 per 1000 people, while the highest mortality rate is in Sierra Leone, with a rate of 131.3 per 1000 population. This suggests that there is a need for greater investment in healthcare and other services in countries with higher mortality rates in order to reduce the number of deaths in this age group.\n"
     ]
    }
   ],
   "source": [
    "print(return_insights(mortality, \"This is data for mortality rates for 5-14 year olds. The key columns are Period (for time), ParentLocation (for country) and FactValueNumeric (the measured mortality rate)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987fcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
